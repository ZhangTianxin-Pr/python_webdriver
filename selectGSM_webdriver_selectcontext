import csv
csvfile=file('chiporg.csv','rb')
reader=csv.reader(csvfile)
c=[row[1:15] for row in reader]
##read csv


i=0
g1=[]
for i,element in enumerate (c):
    if c[i][13].startswith('ChIP-Seq'):
        if c[i][0].startswith('GSM'):
            if c[i][0].lower().find("igg")==-1:  
                if c[i][0].lower().find("input")==-1: 
                    g1.append(c[i][0])
##select GSM
##type(c1[1]) list   
##c[0][0],c[0][5],c[0][13]
##type(c[0][0]) str
##len(g1) 2784



for i,element in enumerate(g1):
    g=''.join(g1[i])
	  gs=g[0:10]
	  gsm.append(gs.rstrip(':'))
#del :  and list to str


#out=open('gsmlist.txt','wb')
#for i,element in enumerate(g1):
#    out.write(str(g1[i])+"\n")
#out.close()
##print txt


csvfile=open('gsmlist.csv','wb')
writer=csv.writer(csvfile, delimiter='\n')
writer.writerow(g1)
csvfile.close()
##write csv
##must be close

#sudo cp -rf  /home/ztx/gsmlist.csv /usr/lib/python2.7/doc
#copy csv to python doc


glist=[]
for i,element in enumerate(gl):
    g=''.join(gl[i])
    glist.append(gl)
##list to str


from selenium import webdriver

import requests
import time
#import urllib2
#import re
#from bs4 import BeautifulSoup as bs


#options = webdriver.ChromeOptions()
#options.binary_location = '/usr/bin/google-chrome'
#options.add_argument('headless')
##set option for chrome (sometimes)


driver = webdriver.Chrome()
url1='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc='
cha=[]
for i,element in enumerate(glist): 
    url=url1+glist[i]
    driver.get(url)
    time.sleep(3)
    con=driver.find_element_by_xpath("//table/tbody/tr/td/table[6]/tbody/tr[3]/td[2]/table/tbody/tr/td/table/tbody/tr/td/table[2]/tbody/tr/td/table/tbody/tr[8]/td[2]")
#   text=con.text.replace('\n',' ')
    cha.append(text.encode('utf-8'))
#utf-8 use to identify α,β

csvfile=open('text.csv','wb')
writer=csv.writer(csvfile, delimiter='\n')   
writer.writerow(cha)
csvfile.close()

anti=[]
for i,element in enumerate(cha):
    if cha[i].find('antibody: ')==-1:
        anti.append('NULL')        
    else: 
        anti.append(cha[i].split("antibody: ")[1].split("\n")[0])
csvfile=open('character.csv','wb')
writer=csv.writer(csvfile, delimiter='\n')   
writer.writerow(anti)
csvfile.close())


del cellline[0]
del cellline[1]
del cellline[2]


#split : select the part of string        
##example
##str="hello boy<[www.doiido.com]>byebye"
##str.split("[")[1].split("]")[0]
##'www.doiido.com'
##str.split("[")[1].split("]")[0].split(".")
##['www', 'doiido', 'com']




#sudo pip install pandas
from pandas import Series,DataFrame
import pandas as pd
#dataframe=pd.DataFrame({'TREATMENT':treatment,'STAGE':stage,'STRAIN':strain,'TISSUE':tissue,'CELLTYPE':celltype,'CELLLINE':cellline,'ANTI':anti,'GSM':gsmlist})
#dataframe.to_csv("table.csv",index=False,sep=' ')


c1={"GSM":gsm}
data1=DataFrame(c1)
data2=DataFrame(anti)
del data2[1]
del data2[2]
del data2[3]
data3=DataFrame(cellline)
del data3[1]
del data3[2]
del data3[3]
data4=DataFrame(celltype)
data5=DataFrame(tissue)
del data5[1]
data6=DataFrame(strain)
del data6[1]
data7=DataFrame(stage)
del data7[1]
data8=DataFrame(treatment)
del data8[10]
#del 1 to 10
result=pd.concat([data1,data2,data3,data4,data5,data6,data7,data8],axis=1)
result.columns=['GSM','factor','cellline','celltype','tissue','strain','stage','treatment']
know=[0]*2784
t1.insert(8,'know',know)
result.to_csv("table.csv",index=False)
#result.to_csv("table.csv",index=False,sep=' ')
#df = pd.read_csv("table5.csv", header=0, sep=',')



#example
#one list change: a=[1,2,3,4]  c={"a" : a}  data=DataFrame(c)  
#list to dictionary to dataframe
#print 
#   a
#0  1
#1  2
#2  3
#3  4
#children list change: a=[[1,2,3,4],[5,6,7,8]]  data=DataFrame(a)
#print
#   0  1  2  3
#0  1  2  3  4
#1  5  6  7  8
#row column change: data=data.T
#data.rename(columns={0:'a',1:'b'},inplace=True)
#print
#   a  b
#0  1  5
#1  2  6
#2  3  7
#3  4  8



df = pd.read_csv("table5.csv", header=0, sep=',')
#df['know'].replace(NaN,'...',inplace=True)
#replace list data
df.loc[3,'know']=df.iloc[3,0]='wap, l(1)C204, N2, pasc'
#insert one data
df.to_csv("table6.csv",index=False)



import csv
import numpy as np
import pandas as pd
df=pd.read_csv("chiporg.csv",header=0,usecols=['Experiment Title','Study Title'], sep=',')
df1=np.array(df)
df2=df1.tolist()
g1=[]
i=0
for i,element in enumerate(df2):
    if df2[i][1].lower().find("chip-seq")==-1:
        del df2[i]
    else:
        g1.append(df2[i])
#study title not find chip-seq then del
#if AttributeError: 'float' object has no attribute 'lower'
#before if ,insert ...     if type(df2[i][1]) is str:
#                  ...         df2[i][1]=df2[i][1].lower()



#df=pd.read_csv('/usr/lib/python2.7/doc/insert_know_context.csv',header=0,sep=',')
#solve the question:IOError: File all.csv does not exist
#insert obsolute path
csvfile=file('drosophila_chipseq_result.csv','rb')
reader=csv.reader(csvfile)
c=[row for row in reader]
c1=[]
i=0
for i,element in enumerate (c):
     if c[i][1].startswith('GSM'):
         c1.append(c[i])
for i,element in enumerate(c1):
     g=c1[i][1]
     c1[i][1]=g[0:10].rstrip(':')
#in total chipseq chart, select GSM and the column only leave gsmID        
df=pd.read_csv('/home/ztx/factor_all_header.csv',header=0,sep=',')
df1=np.array(df)
df2=df1.tolist()        
c2=[]
for i,element in enumerate(df2):
     g2.append(df2[i])
#read factor file and exchange from dataframe to list
j=0
c3=[]
for i,element in enumerate(c1):
     for j,element in enumerate(c2):
         if c1[i][1]==c2[j][0]:
             c3.append(c1[i])
#if factor's GSM in total's GSM, leave
c4=[]
for i,element in enumerate(c3):
    c4.append(c3[i][0])
#finish to find SRX which is matching by GSM
csvfile=open('factor_SRX.csv','wb')
writer=csv.writer(csvfile, delimiter='\n')   
writer.writerow(c4)
csvfile.close()
         
 
 
 
from selenium import webdriver
import requests
import time
driver = webdriver.Chrome()
url1='https://www.ncbi.nlm.nih.gov/sra/?term='
cha=[]
for i,element in enumerate(c4): 
    url=url1+c4[i]
    driver.get(url)
    time.sleep(3)
    results=driver.find_elements_by_xpath("//div[@class='rprt']/div[1]/table/tbody/tr")
    for result in results:
        link=result.find_element_by_xpath(".//td/a")
        cha.append(link.text)
#from SRX page find SRR         
#the output is column should T
#array T: grid = [[row[i] for row in grid] for i in range(len(grid[0]))]  OR list(list(i) for i in zip(*a)) --find the zip()        



protocol=[]
driver = webdriver.Chrome()
url1='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc='
for i,element in enumerate(gsm):
     url=url1+gsm[i]
     driver.get(url)
     time.sleep(3)     
     results=driver.find_elements_by_xpath("//table/tbody/tr/td/table[6]/tbody/tr[3]/td[2]/table/tbody/tr/td/table/tbody/tr/td/table[2]/tbody/tr/td/table/tbody/tr")
     for result in results:
         link=result.find_element_by_xpath(".//td[1]")
         if link.text=='Extraction protocol':
             link1=result.find_element_by_xpath(".//td[2]")
             protocol.append(link1.text)         
#get every GSMID's protocol         
         
   
   

g4=[]
for i,element in enumerate(df2):
    if type(df2[i][1]) is str:
        df2[i][1]=df2[i][1].lower()
        if df2[i][1].find("none")==-1:
            if df2[i][1].find("input")==-1:
                if df2[i][1].find("no antibody")==-1:
                    if df2[i][1].find("wce")==-1:
                        if df2[i][1].find("--")==-1:
                            g4.append(df2[i])
#del factor include:--,no antibody,wce,input,none
#the data from 2784 to 2613
